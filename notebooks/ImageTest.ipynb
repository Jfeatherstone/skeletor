{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab705f19-931f-472d-a9c2-005c3bee01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from skeletor.data import loadImages\n",
    "\n",
    "from pepe.preprocess import checkImageType\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import dask.array as da\n",
    "from dask_image.imread import imread\n",
    "from dask_image.ndmeasure import label\n",
    "from dask_image.ndfilters import convolve\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "import dask.dataframe as dd\n",
    "import pickle\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8a2b4-d727-42d9-bd10-bf35b4f8f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = '/home/jack/Workspaces/data/scans/2024-11-01_LG_C_PNG/'\n",
    "\n",
    "images = loadImages(dataFolder, format='sparse')\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e5a3f-27a0-4408-a015-add483256684",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "greenChannel = 1\n",
    "dataFolder = '/home/jack/Workspaces/data/scans/2024-11-01_LG_C_PNG/'\n",
    "imageExtension = \"png\"\n",
    "\n",
    "start = 0\n",
    "end = None\n",
    "skip = 2\n",
    "threshold = 10\n",
    "dsFactor = 2\n",
    "# End parameters\n",
    "\n",
    "imagePaths = np.sort([f for f in os.listdir(dataFolder) if f[-3:].lower() == imageExtension.lower()])\n",
    "imagePaths = np.array([os.path.join(dataFolder, f) for f in imagePaths if 'mask' not in f])[start:end:skip]\n",
    "\n",
    "print(f'Found {len(imagePaths)} images')\n",
    "testImg = checkImageType(imagePaths[0])\n",
    "\n",
    "print(np.max(testImg))\n",
    "imageData = np.zeros((len(imagePaths), *np.array((testImg.shape[:2]), dtype=np.int64)//dsFactor), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(len(imagePaths))):\n",
    "    binImage = np.mean(checkImageType(imagePaths[i + start]), axis=-1)\n",
    "    binImage[binImage < threshold] = 0\n",
    "    binImage[binImage > 0] = 1\n",
    "    dsImage = binImage[::dsFactor,::dsFactor]\n",
    "    imageData[i] = dsImage\n",
    "    \n",
    "\n",
    "print(imageData.shape)\n",
    "print(np.max(imageData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c00c0-5bc9-4cf7-8486-b5c1c3da1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_3d_image.npy', 'wb') as f:\n",
    "    np.save(f, imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfadfc-bec2-46a2-acd4-06deeca3c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = '/home/jack/Workspaces/data/scans/2024-11-01_LG_C_PNG/'\n",
    "imageExtension = \"png\"\n",
    "threshold = 50\n",
    "dsFactor = 15\n",
    "\n",
    "images = imread(f'{dataFolder}*.{imageExtension}')\n",
    "\n",
    "# Grayscale\n",
    "images = np.mean(images, axis=-1)\n",
    "\n",
    "# Remove the mask\n",
    "images = images[:-1]\n",
    "\n",
    "images = images[::dsFactor,::dsFactor,::dsFactor]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8370872-a400-424b-9de5-a9db587acc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_image.ndfilters\n",
    "\n",
    "smoothedImages = dask_image.ndfilters.gaussian_filter(images, sigma=2)\n",
    "\n",
    "binImages = smoothedImages > threshold\n",
    "\n",
    "binImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f485a-b668-4c2a-9fca-4e7e1bfeedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = np.array([4,10,12])  # even numbers\n",
    "chunksize = np.array(binImages.shape)//factor\n",
    "\n",
    "rechunkBinImages = binImages.rechunk(chunksize)\n",
    "\n",
    "rechunkBinImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff49a5-6137-4377-b06a-b53981edd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel = da.map_overlap(skeletonize, rechunkBinImages)\n",
    "ndim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cecc0d-c85b-47fe-96f0-e35905cef037",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77e340-2a4e-41d2-8fe5-f9ce6679bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each non-zero pixel with a unique integer id\n",
    "structure_kernel = np.zeros((3,) * ndim)\n",
    "structure_kernel[(1,) * ndim] = 1  # add centre pixel\n",
    "skelint, num_features = label(skel, structure=structure_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed865407-45c8-47da-8e0f-f416189eba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each non-zero pixel with the number of neighbors it has\n",
    "degree_kernel = np.ones((3,) * ndim)\n",
    "degree_kernel[(1,) * ndim] = 0  # remove centre pixel\n",
    "degrees_image = convolve(skel.astype(int), degree_kernel, mode='constant') * skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940123fb-7086-46bc-a483-07ce3008071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mofified from slices_from_chunks from dask.array.core\n",
    "from itertools import product\n",
    "from dask.array.slicing import cached_cumsum\n",
    "\n",
    "\n",
    "def slices_from_chunks_overlap(chunks, array_shape, depth=1):\n",
    "    \"\"\"Translate chunks tuple to a set of slices in product order\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunks : tuple\n",
    "        The chunks of the corresponding dask array.\n",
    "    array_shape : tuple\n",
    "        Shape of the corresponding dask array.\n",
    "    depth : int\n",
    "        The number of pixels to overlap, providing we're not at the array edge.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> slices_from_chunks_overlap(((4,), (7, 7)), (4, 14), depth=1)  # doctest: +NORMALIZE_WHITESPACE\n",
    "     [(slice(0, 5, None), slice(0, 8, None)),\n",
    "      (slice(0, 5, None), slice(6, 15, None))]\n",
    "    \"\"\"\n",
    "    cumdims = [cached_cumsum(bds, initial_zero=True) for bds in chunks]\n",
    "\n",
    "    slices = []\n",
    "    for starts, shapes in zip(cumdims, chunks):\n",
    "        inner_slices = []\n",
    "        for s, dim, maxshape in zip(starts, shapes, array_shape):\n",
    "            slice_start = s\n",
    "            slice_stop = s + dim\n",
    "            if slice_start > 0:\n",
    "                slice_start -= depth\n",
    "            if slice_stop >= maxshape:\n",
    "                slice_stop += depth\n",
    "            inner_slices.append(slice(slice_start, slice_stop))\n",
    "        slices.append(inner_slices)\n",
    "    \n",
    "    return list(product(*slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6aafd-1a69-498b-abcc-1f83128924e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.delayed import delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from skan.nputil import raveled_steps_to_neighbors\n",
    "from skan.csr import _write_pixel_graph\n",
    "\n",
    "\n",
    "@delayed\n",
    "def skeleton_graph_func(skelint, spacing=1):\n",
    "    ndim = skelint.ndim\n",
    "    spacing = np.ones(ndim, dtype=float) * spacing\n",
    "    num_edges = _num_edges(skelint.astype(bool))\n",
    "    padded_skelint = np.pad(skelint, 1)  # pad image to prevent looparound errors\n",
    "    steps, distances = raveled_steps_to_neighbors(padded_skelint.shape, ndim,\n",
    "                                                  spacing=spacing)\n",
    "\n",
    "    # from function skan.csr._pixel_graph\n",
    "    row = np.empty(num_edges, dtype=int)\n",
    "    col = np.empty(num_edges, dtype=int)\n",
    "    data = np.empty(num_edges, dtype=float)\n",
    "    k = _write_pixel_graph(padded_skelint, steps, distances, row, col, data)\n",
    "\n",
    "    return pd.DataFrame({\"row\": row, \"col\": col, \"data\": data})\n",
    "Alongside indexing assignment and retrieval, DOK arrays support any arbitrary broadcasting function to any number of arguments where the arguments can be SparseArray objects, scipy.sparse.spmatrix objects, or numpy.ndarrays.\n",
    "\n",
    "x = sparse.random((10, 10), 0.5, format=\"dok\")\n",
    "y = sparse.random((10, 10), 0.5, format=\"dok\")\n",
    "sparse.elemwise(np.add, x, y)\n",
    "\n",
    "\n",
    "def _num_edges(skel):\n",
    "    degree_kernel = np.ones((3,) * ndim)\n",
    "    degree_kernel[(1,) * ndim] = 0  # remove centre pixel\n",
    "    degree_image = scipy.ndimage.convolve(skel.astype(int),\n",
    "                                          degree_kernel,\n",
    "                                          mode='constant') * skel\n",
    "    num_edges = np.sum(degree_image)\n",
    "    return int(num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2dd67-883b-4ab6-873e-4269fc4ca5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the results we need to make the skeleton graph\n",
    "image = skelint\n",
    "block_iter = zip(\n",
    "    np.ndindex(*image.numblocks),\n",
    "    map(functools.partial(operator.getitem, image),\n",
    "        slices_from_chunks_overlap(image.chunks, image.shape, depth=1))\n",
    ")\n",
    "\n",
    "meta = dd.utils.make_meta([('row', np.int64), ('col', np.int64), ('data', np.float64)])  # it's very important to include meta\n",
    "intermediate_results = [dd.from_delayed(skeleton_graph_func(block), meta=meta) for _, block in block_iter]  # this appears to be triggering a lot of computation\n",
    "results = dd.concat(intermediate_results)\n",
    "results = results.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c984a-9121-4651-8bb1-13a2b9025aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the skeleton graph adjacency matrix\n",
    "k = len(results)\n",
    "print(k)\n",
    "row = np.array(results['row'])\n",
    "col = np.array(results['col'])\n",
    "data = np.array(results['data'])\n",
    "\n",
    "graph = sparse.coo_matrix((data[:k], (row[:k], col[:k]))).tocsr()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7e336-0b9f-462f-9714-53a005e06925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(float(skel[1][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c15ba-67e8-4bf3-b241-bbd2f94dfcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../2024-10-11_LG_A_PNG_sparse_skeleton.pckl', 'rb') as f:\n",
    "    sparseImage = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc2ae1-09c5-4795-9723-7bffbe70fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014ee3a-362c-4123-abc9-f37b97f39856",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePoints = sparseImage.coords.T\n",
    "\n",
    "pointCloudClean = o3d.geometry.PointCloud()\n",
    "pointCloudClean.points = o3d.utility.Vector3dVector(imagePoints)\n",
    "pointCloudClean.paint_uniform_color((1, 0, 0))\n",
    "\n",
    "o3d.visualization.draw_geometries([pointCloudClean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc5b33-225d-438e-bba1-cf545a8ef3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
