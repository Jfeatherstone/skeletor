{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f3e72-c2a1-4b56-b920-597dcc9a3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "import cv2\n",
    "from itertools import product\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from skeletor.utils import courseGrainField, pathIntegralAlongField\n",
    "\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0163cc-fa7b-40f6-aa2a-e295937c4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.random.uniform(1, 2, size=(50,2))\n",
    "\n",
    "plt.scatter(*points.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d0edc-6b52-45df-b961-f47f0bc7ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latticeSpacing = .02\n",
    "field, corner = courseGrainField(points, latticeSpacing=latticeSpacing, kernelSize=11, returnCorner=True)\n",
    "print(corner)\n",
    "plt.pcolor(field)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff0c09-e3ec-414f-b44e-baab54059a66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def product(*iterables, repeat=1):\n",
    "    # product('ABCD', 'xy') → Ax Ay Bx By Cx Cy Dx Dy\n",
    "    # product(range(2), repeat=3) → 000 001 010 011 100 101 110 111\n",
    "\n",
    "    pools = [tuple(pool) for pool in iterables] * repeat\n",
    "\n",
    "    result = [[]]\n",
    "    for pool in pools:\n",
    "        result = [x+[y] for x in result for y in pool]\n",
    "\n",
    "    for prod in result:\n",
    "        yield tuple(prod)\n",
    "\n",
    "@numba.njit()\n",
    "def pathIntegralAlongFieldFast(field, path, latticeSpacing=1, fieldOffset=None, debug=False):\n",
    "    \"\"\"\n",
    "    Computes the path integral along a scalar discretized field in any\n",
    "    dimension.\n",
    "\n",
    "    Uses linear interpolation along the path, so works the best for smoothly-\n",
    "    varying fields.\n",
    "\n",
    "    Does not interpolate the steps along the path, so the input path steps\n",
    "    should be appropriately broken up.\n",
    "\n",
    "    Make sure that all of the quantities passed to this method use the same\n",
    "    ordering of dimensions! For example, if you are integrating across an\n",
    "    image, these often use y-x convention, whereas you may be tempted to\n",
    "    put your path information in x-y format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : numpy.ndarray[N,M,...]\n",
    "        Field over which to compute the path integral.\n",
    "\n",
    "    path : numpy.ndarray[L,d]\n",
    "        L ordered points representing a path\n",
    "        through the field.\n",
    "\n",
    "    latticeSpacing : float, or numpy.ndarray[d]\n",
    "        The lattice spacing for the discretized field;\n",
    "        can be a single value for all dimensions, or different\n",
    "        values for each dimension.\n",
    "\n",
    "    fieldOffset : numpy.ndarray[d] or None\n",
    "        The position of the bottom left corner\n",
    "        of the discrete lattice on which the field exists.\n",
    "\n",
    "    debug : bool\n",
    "        Whether to plot diagnostic information about the field\n",
    "        and path. Only works if field is two dimensional.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : float\n",
    "    \"\"\"\n",
    "    d = field.ndim\n",
    "    \n",
    "    # Scale the path to have no units\n",
    "    scaledPath = path.astype(np.float64)\n",
    "    \n",
    "    if fieldOffset is not None:\n",
    "        scaledPath -= fieldOffset\n",
    "    \n",
    "    scaledPath /= latticeSpacing\n",
    "\n",
    "    nearbyIndices = []\n",
    "    for i in range(len(scaledPath)):\n",
    "        #print(scaledPath[i])\n",
    "        possibleIndices = []\n",
    "        for j in range(d):\n",
    "            possibleIndices.append(np.unique(np.array([np.floor(scaledPath[i,j]), np.ceil(scaledPath[i,j])])))\n",
    "        #possibleIndices = np.array(possibleIndices)\n",
    "        totalCombinations = int(np.nanprod(np.array([np.float64(len(p)) for p in possibleIndices])))\n",
    "        \n",
    "        # possibleIndices = [list(np.floor(scaledPath[i])), list(np.ceil(scaledPath[i]))]\n",
    "        # possibleIndices = np.array(possibleIndices).T\n",
    "\n",
    "        result = np.zeros((totalCombinations, d))\n",
    "        result[:,0] = np.repeat(possibleIndices[0], totalCombinations // len(possibleIndices[1]))\n",
    "        result[:,1] = list(possibleIndices[1])*(totalCombinations // len(possibleIndices[0]))\n",
    "        #print(result)\n",
    "        # This next part is mostly copied from itertools' product\n",
    "        # function.\n",
    "        #result = [[]]\n",
    "        #for pool in possibleIndices:\n",
    "        #   result = [x+[y] for x in result for y in pool]\n",
    "            \n",
    "        #print(result)\n",
    "        # Removing duplicate indices (in case the path includes an exact integer\n",
    "        # as a point) is faster one the entire list afterwards, instead\n",
    "        # of doing a bunch of calls here.\n",
    "        #possibleIndices = np.unique(possibleIndices, axis=-1)\n",
    "        #possibleIndices = np.array([np.unique(p) for p in possibleIndices])\n",
    "        #nearbyIndices.append(np.array(list(product(*possibleIndices))))\n",
    "        nearbyIndices.append(result)\n",
    "\n",
    "    \n",
    "    fieldValuesAlongPath = np.zeros(len(scaledPath))\n",
    "\n",
    "    for i in range(len(scaledPath)):\n",
    "        #localPoints = np.unique(nearbyIndices[i], axis=0)\n",
    "        localPoints = nearbyIndices[i]\n",
    "        #print(localPoints)\n",
    "        # Compute distances to each nearby point\n",
    "        localDistances = np.sqrt(np.sum((scaledPath[i] - localPoints)**2, axis=-1))\n",
    "        interpolationContributions = localDistances / np.sum(localDistances)\n",
    "        # Now weight the values at the nearby points by their distances\n",
    "        #fieldValuesAlongPath[i] = np.sum(interpolationContributions * np.array([field[tuple(np.int32(p))] for p in localPoints]))\n",
    "        #print(field[tuple(localPoints.astype(np.int32).T)])\n",
    "        #print(interpolationContributions)\n",
    "        #print(np.int32(localPoints).T)\n",
    "        #TODO\n",
    "        #fieldValues = #np.take(field, localPoints.astype(np.int64))\n",
    "        #fieldValuesAlongPath[i] = np.nansum(interpolationContributions * field[tuple(localPoints.astype(np.int32).T)])\n",
    "        for j in range(d**2):\n",
    "            fieldValue = field\n",
    "            for k in range(d):\n",
    "                fieldValue = fieldValue[int(localPoints[j][k])]\n",
    "            \n",
    "            #print(type(localPoints))\n",
    "            #index = (localPoints.astype(np.int64)[j][0], localPoints.astype(np.int64)[j][1])\n",
    "            #print(field[index])\n",
    "            fieldValuesAlongPath[i] += interpolationContributions[j] * fieldValue\n",
    "\n",
    "    # We need to weigh our numerical integration by the step size\n",
    "    # We just to do a centered step scheme. ie. the interpolated value computed\n",
    "    # above for point i \"counts\" for half of the path approaching point i, and\n",
    "    # half of the path leaving point i. Thus, the first and last point are weighed\n",
    "    # only half, since they don't have an incoming or outgoing path each.\n",
    "    # We also have to scale back to the original lattice spacing.\n",
    "    pathSpacings = np.sqrt(np.sum(((scaledPath[1:] - scaledPath[:-1])/latticeSpacing)**2, axis=-1))\n",
    "    symSpacing = (pathSpacings[:-1] + pathSpacings[1:])/2\n",
    "    symSpacing = np.concatenate((np.array([pathSpacings[0]/2]), symSpacing, np.array([pathSpacings[-1]/2])))\n",
    "\n",
    "    pathIntegral = np.sum(symSpacing*fieldValuesAlongPath)\n",
    "    \n",
    "    # if debug and d == 2:\n",
    "    #     axes = [np.arange(d) for d in np.shape(field)]\n",
    "    #     points = np.array(np.meshgrid(*axes, indexing='ij')).T\n",
    "    #     points = points.reshape(np.product(points.shape[:-1]), points.shape[-1])\n",
    "\n",
    "    #     plt.imshow(field) # imshow reverses reads y,x, while the other two do x,y\n",
    "    #     plt.scatter(*points.T[::-1], s=1, c='white')\n",
    "    #     plt.plot(*scaledPath.T[::-1], '-o', c='red', markersize=2)\n",
    "    #     plt.show()\n",
    "    \n",
    "    return pathIntegral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd416541-4a14-4a49-b9f6-99630fe7870b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pathIntegralAlongField(field, path, latticeSpacing=1, fieldOffset=None, debug=False):\n",
    "    \"\"\"\n",
    "    Computes the path integral along a scalar discretized field in any\n",
    "    dimension.\n",
    "\n",
    "    Uses linear interpolation along the path, so works the best for smoothly-\n",
    "    varying fields.\n",
    "\n",
    "    Does not interpolate the steps along the path, so the input path steps\n",
    "    should be appropriately broken up.\n",
    "\n",
    "    Make sure that all of the quantities passed to this method use the same\n",
    "    ordering of dimensions! For example, if you are integrating across an\n",
    "    image, these often use y-x convention, whereas you may be tempted to\n",
    "    put your path information in x-y format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : numpy.ndarray[N,M,...]\n",
    "        Field over which to compute the path integral.\n",
    "\n",
    "    path : numpy.ndarray[L,d]\n",
    "        L ordered points representing a path\n",
    "        through the field.\n",
    "\n",
    "    latticeSpacing : float, or numpy.ndarray[d]\n",
    "        The lattice spacing for the discretized field;\n",
    "        can be a single value for all dimensions, or different\n",
    "        values for each dimension.\n",
    "\n",
    "    fieldOffset : numpy.ndarray[d] or None\n",
    "        The position of the bottom left corner\n",
    "        of the discrete lattice on which the field exists.\n",
    "\n",
    "    debug : bool\n",
    "        Whether to plot diagnostic information about the field\n",
    "        and path. Only works if field is two dimensional.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : float\n",
    "    \"\"\"\n",
    "    d = np.array(field).ndim\n",
    "\n",
    "    if not hasattr(latticeSpacing, '__iter__'):\n",
    "        spacing = np.repeat(latticeSpacing, d)\n",
    "    else:\n",
    "        spacing = latticeSpacing\n",
    "        \n",
    "    if d == 2 and not debug:\n",
    "        return _pathIntegralAlongField2D(field, path, spacing, fieldOffset)\n",
    "    elif d == 3 and not debug:\n",
    "        return _pathIntegralAlongField3D(field, path, spacing, fieldOffset)\n",
    "    else:\n",
    "        return _pathIntegralAlongFieldMulti(field, path, spacing, fieldOffset, debug)\n",
    "    \n",
    "@numba.njit()\n",
    "def _pathIntegralAlongField2D(field, path, latticeSpacing=1, fieldOffset=None):\n",
    "    \"\"\"\n",
    "    numba-optimized function to compute a path integral in 2D; designed\n",
    "    to be called by `pathIntegralAlongField()` only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : numpy.ndarray[N,M]\n",
    "        Field over which to compute the path integral.\n",
    "\n",
    "    path : numpy.ndarray[L,2]\n",
    "        L ordered points representing a path\n",
    "        through the field.\n",
    "\n",
    "    latticeSpacing : float, or numpy.ndarray[2]\n",
    "        The lattice spacing for the discretized field;\n",
    "        can be a single value for all dimensions, or different\n",
    "        values for each dimension.\n",
    "\n",
    "    fieldOffset : numpy.ndarray[2] or None\n",
    "        The position of the bottom left corner\n",
    "        of the discrete lattice on which the field exists.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : float\n",
    "    \"\"\"\n",
    "    d = field.ndim\n",
    "    \n",
    "    # Scale the path to have no units\n",
    "    scaledPath = path.astype(np.float64)\n",
    "    \n",
    "    if fieldOffset is not None:\n",
    "        scaledPath -= fieldOffset\n",
    "    \n",
    "    for i in range(d):\n",
    "        scaledPath[:,i] /= latticeSpacing[i]\n",
    "\n",
    "    nearbyIndices = []\n",
    "    for i in range(len(scaledPath)):\n",
    "        possibleIndices = []\n",
    "        for j in range(d):\n",
    "            possibleIndices.append(np.array([np.floor(scaledPath[i,j]), np.ceil(scaledPath[i,j])]))\n",
    "        totalCombinations = int(np.prod(np.array([np.float64(len(p)) for p in possibleIndices])))\n",
    "\n",
    "        # Have to manually index to make numba happy\n",
    "        result = np.zeros((totalCombinations, d))\n",
    "        result[:,0] = np.repeat(possibleIndices[0], totalCombinations // len(possibleIndices[1]))\n",
    "        result[:,1] = list(possibleIndices[1])*(totalCombinations // len(possibleIndices[0]))\n",
    "            \n",
    "        nearbyIndices.append(result)\n",
    "\n",
    "    fieldValuesAlongPath = np.zeros(len(scaledPath))\n",
    "\n",
    "    for i in range(len(scaledPath)):\n",
    "        localPoints = nearbyIndices[i]\n",
    "        # Compute distances to each nearby point\n",
    "        # Add some tiny amount to avoid divide by zero issues\n",
    "        localDistances = np.sqrt(np.sum((scaledPath[i] - localPoints)**2, axis=-1)) + 1e-10\n",
    "        interpolationContributions = localDistances / np.sum(localDistances)\n",
    "\n",
    "        # Have to do some weird indexing to make numba happy, but generally this is\n",
    "        # just the dot product between interpolationContributions and field[all indices]\n",
    "        for j in range(2**d):\n",
    "            index = (int(localPoints[j][0]), int(localPoints[j][1]))\n",
    "            fieldValuesAlongPath[i] += interpolationContributions[j] * field[index]\n",
    "\n",
    "    # We need to weigh our numerical integration by the step size\n",
    "    # We just to do a centered step scheme. ie. the interpolated value computed\n",
    "    # above for point i \"counts\" for half of the path approaching point i, and\n",
    "    # half of the path leaving point i. Thus, the first and last point are weighed\n",
    "    # only half, since they don't have an incoming or outgoing path each.\n",
    "    # We also have to scale back to the original lattice spacing.\n",
    "    unscaledPath = scaledPath[1:] - scaledPath[:-1]\n",
    "    for i in range(d):\n",
    "        unscaledPath[:,i] *= latticeSpacing[i]\n",
    "        \n",
    "    pathSpacings = np.sqrt(np.sum((unscaledPath)**2, axis=-1))\n",
    "    symSpacing = (pathSpacings[:-1] + pathSpacings[1:])/2\n",
    "    symSpacing = np.concatenate((np.array([pathSpacings[0]/2]), symSpacing, np.array([pathSpacings[-1]/2])))\n",
    "    \n",
    "    pathIntegral = np.sum(symSpacing*fieldValuesAlongPath)\n",
    "        \n",
    "    return pathIntegral\n",
    "\n",
    "\n",
    "@numba.njit()\n",
    "def _pathIntegralAlongField3D(field, path, latticeSpacing=1, fieldOffset=None):\n",
    "    \"\"\"\n",
    "    numba-optimized function to compute a path integral in 3D; designed\n",
    "    to be called by `pathIntegralAlongField()` only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : numpy.ndarray[N,M,...]\n",
    "        Field over which to compute the path integral.\n",
    "\n",
    "    path : numpy.ndarray[L,d]\n",
    "        L ordered points representing a path\n",
    "        through the field.\n",
    "\n",
    "    latticeSpacing : float, or numpy.ndarray[d]\n",
    "        The lattice spacing for the discretized field;\n",
    "        can be a single value for all dimensions, or different\n",
    "        values for each dimension.\n",
    "\n",
    "    fieldOffset : numpy.ndarray[d] or None\n",
    "        The position of the bottom left corner\n",
    "        of the discrete lattice on which the field exists.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : float\n",
    "    \"\"\"\n",
    "    d = field.ndim\n",
    "    \n",
    "    # Scale the path to have no units\n",
    "    scaledPath = path.astype(np.float64)\n",
    "    \n",
    "    if fieldOffset is not None:\n",
    "        scaledPath -= fieldOffset\n",
    "\n",
    "    for i in range(d):\n",
    "        scaledPath[:,i] /= latticeSpacing[i]\n",
    "\n",
    "    nearbyIndices = []\n",
    "    for i in range(len(scaledPath)):\n",
    "        possibleIndices = []\n",
    "        for j in range(d):\n",
    "            possibleIndices.append(np.array([np.floor(scaledPath[i,j]), np.ceil(scaledPath[i,j])]))\n",
    "        totalCombinations = int(np.nanprod(np.array([np.float64(len(p)) for p in possibleIndices])))\n",
    "\n",
    "        # Have to manually index to make numba happy\n",
    "        result = np.zeros((totalCombinations, d))\n",
    "        result[:,0] = np.repeat(possibleIndices[0], 4)\n",
    "        result[:,1] = list(possibleIndices[1]) * 4\n",
    "        result[:,2] = list(np.repeat(possibleIndices[2], 2)) * 2\n",
    "        #print(result)\n",
    "        nearbyIndices.append(result)\n",
    "\n",
    "    fieldValuesAlongPath = np.zeros(len(scaledPath))\n",
    "\n",
    "    for i in range(len(scaledPath)):\n",
    "        localPoints = nearbyIndices[i]\n",
    "        # Compute distances to each nearby point\n",
    "        # Add some tiny amount to avoid divide by zero issues\n",
    "        localDistances = np.sqrt(np.sum((scaledPath[i] - localPoints)**2, axis=-1)) + 1e-10\n",
    "        interpolationContributions = localDistances / np.sum(localDistances)\n",
    "\n",
    "        # Have to do some weird indexing to make numba happy, but generally this is\n",
    "        # just the dot product between interpolationContributions and field[all indices]\n",
    "        for j in range(2**d):\n",
    "            index = (int(localPoints[j][0]), int(localPoints[j][1]), int(localPoints[j][2]))\n",
    "            fieldValuesAlongPath[i] += interpolationContributions[j] * field[index]\n",
    "\n",
    "    # We need to weigh our numerical integration by the step size\n",
    "    # We just to do a centered step scheme. ie. the interpolated value computed\n",
    "    # above for point i \"counts\" for half of the path approaching point i, and\n",
    "    # half of the path leaving point i. Thus, the first and last point are weighed\n",
    "    # only half, since they don't have an incoming or outgoing path each.\n",
    "    # We also have to scale back to the original lattice spacing.\n",
    "    unscaledPath = scaledPath[1:] - scaledPath[:-1]\n",
    "    for i in range(d):\n",
    "        unscaledPath[:,i] *= latticeSpacing[i]\n",
    "        \n",
    "    pathSpacings = np.sqrt(np.sum((unscaledPath)**2, axis=-1))\n",
    "    symSpacing = (pathSpacings[:-1] + pathSpacings[1:])/2\n",
    "    symSpacing = np.concatenate((np.array([pathSpacings[0]/2]), symSpacing, np.array([pathSpacings[-1]/2])))\n",
    "\n",
    "    pathIntegral = np.sum(symSpacing*fieldValuesAlongPath)\n",
    "        \n",
    "    return pathIntegral\n",
    "\n",
    "def _pathIntegralAlongFieldMulti(field, path, latticeSpacing=1, fieldOffset=None, debug=False):\n",
    "    \"\"\"\n",
    "    Unoptimized path integral function, but can be used in\n",
    "    an arbitrary spatial dimension, and give debug information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : numpy.ndarray[N,M,...]\n",
    "        Field over which to compute the path integral.\n",
    "\n",
    "    path : numpy.ndarray[L,d]\n",
    "        L ordered points representing a path\n",
    "        through the field.\n",
    "\n",
    "    latticeSpacing : float, or numpy.ndarray[d]\n",
    "        The lattice spacing for the discretized field;\n",
    "        can be a single value for all dimensions, or different\n",
    "        values for each dimension.\n",
    "\n",
    "    fieldOffset : numpy.ndarray[d] or None\n",
    "        The position of the bottom left corner\n",
    "        of the discrete lattice on which the field exists.\n",
    "\n",
    "    debug : bool\n",
    "        Whether to plot diagnostic information about the field\n",
    "        and path. Only works if field is two dimensional.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : float\n",
    "    \"\"\"\n",
    "    d = field.ndim\n",
    "\n",
    "    # Scale the path to have no units\n",
    "    scaledPath = path.astype(np.float64)\n",
    "\n",
    "    if fieldOffset is not None:\n",
    "        scaledPath -= fieldOffset\n",
    "\n",
    "    scaledPath /= latticeSpacing\n",
    "\n",
    "    nearbyIndices = []\n",
    "    for i in range(len(scaledPath)):\n",
    "        possibleIndices = [np.floor(scaledPath[i]), np.ceil(scaledPath[i])]\n",
    "        # We don't need to worry about duplicates if floor(i) == ceil(i)\n",
    "        # since we normalize the contributions at the end.\n",
    "        possibleIndices = np.array(possibleIndices).T\n",
    "\n",
    "        # This next part is mostly copied from itertools' product\n",
    "        # function.\n",
    "        result = [[]]\n",
    "        for pool in possibleIndices:\n",
    "           result = [x+[y] for x in result for y in pool]\n",
    "\n",
    "        nearbyIndices.append(np.array(result))\n",
    "\n",
    "    fieldValuesAlongPath = np.zeros(len(scaledPath))\n",
    "\n",
    "    for i in range(len(scaledPath)):\n",
    "        localPoints = nearbyIndices[i]\n",
    "        # Compute distances to each nearby point\n",
    "        # Add some tiny amount to avoid divide by zero issues\n",
    "        localDistances = np.sqrt(np.sum((scaledPath[i] - localPoints)**2, axis=-1)) + 1e-10\n",
    "        \n",
    "        interpolationContributions = localDistances / np.sum(localDistances)\n",
    "        # Now weight the values at the nearby points by their distances\n",
    "        fieldValuesAlongPath[i] = np.nansum(interpolationContributions * field[tuple(localPoints.astype(np.int32).T)])\n",
    "\n",
    "    # We need to weigh our numerical integration by the step size\n",
    "    # We just to do a centered step scheme. ie. the interpolated value computed\n",
    "    # above for point i \"counts\" for half of the path approaching point i, and\n",
    "    # half of the path leaving point i. Thus, the first and last point are weighed\n",
    "    # only half, since they don't have an incoming or outgoing path each.\n",
    "    # We also have to scale back to the original lattice spacing.\n",
    "    pathSpacings = np.sqrt(np.sum(((scaledPath[1:] - scaledPath[:-1]) * latticeSpacing)**2, axis=-1))\n",
    "    symSpacing = (pathSpacings[:-1] + pathSpacings[1:])/2\n",
    "    symSpacing = np.concatenate((np.array([pathSpacings[0]/2]), symSpacing, np.array([pathSpacings[-1]/2])))\n",
    "    \n",
    "    pathIntegral = np.sum(symSpacing*fieldValuesAlongPath)\n",
    "\n",
    "    if debug and d == 2:\n",
    "        axes = [np.arange(d) for d in np.shape(field)]\n",
    "        points = np.array(np.meshgrid(*axes, indexing='ij')).T\n",
    "        points = points.reshape(np.product(points.shape[:-1]), points.shape[-1])\n",
    "        \n",
    "        plt.imshow(field) # imshow reverses reads y,x, while the other two do x,y\n",
    "        plt.scatter(*points.T[::-1], s=1, c='white')\n",
    "        plt.plot(*scaledPath.T[::-1], '-o', c='red', markersize=2)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    return pathIntegral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1acca8-9291-4505-a684-f6e7b36d7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33633dad-50d9-4186-9032-5a89f7c89629",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = np.array([1.2, 1.2]) + np.array([x*np.array([.5, .5]) for x in np.linspace(0, 1, 50)])\n",
    "\n",
    "pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd0b49-897c-42e7-9283-e3fd26269842",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = np.array([1.2, 1.2]) + np.array([x*np.array([.5, .5]) for x in np.linspace(0, 1, 50)])\n",
    "\n",
    "pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a1183-0558-40b5-8b6b-061a976f07c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit _pathIntegralAlongField2D(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner)\n",
    "%timeit pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc9918-7095-4f2e-952f-739097960911",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneField = np.ones((50,50))\n",
    "onePath = np.array([1., 1.]) + np.array([x*np.array([0., 5.]) for x in np.linspace(0, 1, 50)])\n",
    "\n",
    "pathIntegralAlongField(oneField, onePath, latticeSpacing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562e0c5-a518-4123-96a5-6f4996d458e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.random.uniform(1, 2, size=(500,3))\n",
    "\n",
    "latticeSpacing = .02\n",
    "field, corner = courseGrainField(points, latticeSpacing=latticeSpacing, kernelSize=11, returnCorner=True)\n",
    "print(corner)\n",
    "\n",
    "path = np.array([1.1, 1.1, 1.1]) + np.array([x*np.array([.8, .8, .8]) for x in np.linspace(0, 1, 500)])\n",
    "\n",
    "print(pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner))\n",
    "print(_pathIntegralAlongField3D(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ff4e7-8ed7-4efb-8948-726a06eddeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit _pathIntegralAlongField3D(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner)\n",
    "%timeit pathIntegralAlongField(field, path, latticeSpacing=latticeSpacing, fieldOffset=corner, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb49e3d-ea34-447a-8dca-d7ac08f2e59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
